{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: questa esercitazione non è da considerarsi completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping di Frame in WordNet synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:24:25.428242Z",
     "start_time": "2023-05-16T19:24:25.424678Z"
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from random import randint\n",
    "from random import seed\n",
    "import string\n",
    "from nltk.corpus import framenet as fn, stopwords, wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il seguente metodo, fornito a lezione, permette di generare un set di ID di FrameNet da usare durante l'esercitazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:23:00.495617Z",
     "start_time": "2023-05-16T19:23:00.488314Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_frame_set_for_student(surname, list_len=5):\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('\\nstudent: ' + surname)\n",
    "    framenet_IDs = [f.ID for f in fn.frames()]\n",
    "    i = 0\n",
    "    offset = 0\n",
    "    seed(1)\n",
    "    my_ids = []\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx + offset) % nof_frames]\n",
    "        my_ids.append(fID)\n",
    "        f = fn.frame(fID)\n",
    "        fNAME = f['name']\n",
    "        print(f'\\tID: {fID:4d}\\tframe: {fNAME}')\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1\n",
    "    return my_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:23:18.940859Z",
     "start_time": "2023-05-16T19:23:16.426760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "student: Mario Bifulco\n",
      "\tID:   12\tframe: Feigning\n",
      "\tID: 2615\tframe: Noncombatant\n",
      "\tID: 2622\tframe: Endeavor_failure\n",
      "\tID: 2664\tframe: Inhibit_motion_scenario\n",
      "\tID:   31\tframe: Scrutiny\n"
     ]
    }
   ],
   "source": [
    "ids = get_frame_set_for_student('Mario Bifulco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare di svolgere più chiamate a FrameNet, ho deciso di riorganizzare le informazioni rilevanti in una semplice classe che raccoglie tutte le parole da disambiguare del frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:23:49.389796Z",
     "start_time": "2023-05-16T19:23:49.380366Z"
    }
   },
   "outputs": [],
   "source": [
    "class MFrame:\n",
    "    def __init__(self, frame_id):\n",
    "        self.id = frame_id\n",
    "        self.name = fn.frame(frame_id)['name']\n",
    "        self.fes = []\n",
    "        for fe in fn.frame(frame_id)['FE']:\n",
    "            self.fes.append(fe)\n",
    "        self.lus = []\n",
    "        for lu in fn.frame(frame_id)['lexUnit']:\n",
    "            self.lus.append(lu)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.name}:\\n\\tFEs: {self.fes}\\n\\tLUs: {self.lus}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def get_words(self):\n",
    "        res = [self.name]\n",
    "        res.extend(self.fes)\n",
    "        res.extend(self.lus)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per trovare il senso a partire dal termine, e dal contesto, utilizzo l'algoritmo Lesk con approccio bag-of-words, rimuovendo le stopwords come operazione di preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:29:23.807778Z",
     "start_time": "2023-05-16T19:29:23.806180Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(phrase):\n",
    "    phrase = phrase.split()\n",
    "    for p in string.punctuation:\n",
    "        phrase = {item.replace(p, '') for item in phrase}\n",
    "    phrase = {item.replace('\\'s', '') for item in phrase}\n",
    "    stop = stopwords.words('english')\n",
    "    return {t for t in phrase if t not in stop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:29:24.088326Z",
     "start_time": "2023-05-16T19:29:24.078527Z"
    }
   },
   "outputs": [],
   "source": [
    "def lesk(word, ctx_w):\n",
    "    split_w = word.split('.')\n",
    "    pos = None\n",
    "    if len(split_w) == 2:\n",
    "        word = split_w[0]\n",
    "        pos = split_w[1]\n",
    "    synset = wn.synsets(word, pos=pos)\n",
    "    if synset is None or len(synset) == 0:\n",
    "        return None\n",
    "    guess = synset[0]\n",
    "    max_overlap = 0\n",
    "    ctx_w = remove_stopwords(ctx_w)\n",
    "    for sense in synset:\n",
    "        ctx_s = remove_stopwords(sense.definition())\n",
    "        ext_s = sense.hypernyms()\n",
    "        ext_s.extend(sense.hyponyms())\n",
    "        for s in ext_s:\n",
    "            ctx_s.add(str(s).split('.')[0][8:])\n",
    "        for ex in sense.examples():\n",
    "            ctx_s.union(remove_stopwords(ex))\n",
    "        overlap = len(ctx_s.intersection(ctx_w))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            guess = sense\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T19:29:26.688538Z",
     "start_time": "2023-05-16T19:29:26.525224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: Feigning                  - Synset('pretense.n.02')  \n",
      "  1: Agent                     - Synset('agent.n.02')     \n",
      "  2: Original                  - Synset('original.s.02')  \n",
      "  3: Copy                      - Synset('transcript.n.02')\n",
      "  4: Manner                    - Synset('manner.n.02')    \n",
      "  5: Means                     - Synset('means.n.01')     \n",
      "  6: Degree                    - Synset('degree.n.01')    \n",
      "  7: State_of_affairs          - Synset('situation.n.01') \n",
      "  8: Purpose                   - Synset('purpose.n.01')   \n",
      "  9: Explanation               - Synset('explanation.n.01')\n",
      " 10: Frequency                 - Synset('frequency.n.01') \n",
      " 11: Time                      - Synset('time.n.06')      \n",
      " 12: Period_of_iterations      - None                     \n",
      " 13: Duration                  - Synset('duration.n.01')  \n",
      " 14: Depictive                 - Synset('delineative.s.01')\n",
      " 15: Circumstances             - Synset('fortune.n.04')   \n",
      " 16: Place                     - Synset('place.n.02')     \n",
      " 17: counterfeit.v             - Synset('forge.v.02')     \n",
      " 18: fake.v                    - Synset('forge.v.02')     \n",
      " 19: feign.v                   - Synset('feign.v.01')     \n",
      " 20: stage.v                   - Synset('stage.v.01')     \n",
      " 21: affect.v                  - Synset('affect.v.01')    \n",
      " 22: pretend.v                 - Synset('feign.v.01')     \n",
      " 23: simulate.v                - Synset('imitate.v.01')   \n",
      "  0: Noncombatant              - Synset('noncombatant.s.01')\n",
      "  1: Origin                    - Synset('beginning.n.04') \n",
      "  2: Person                    - Synset('person.n.01')    \n",
      "  3: Persistent_characteristic - None                     \n",
      "  4: Descriptor                - Synset('form.n.01')      \n",
      "  5: Age                       - Synset('age.n.01')       \n",
      "  6: Ethnicity                 - Synset('ethnicity.n.01') \n",
      "  7: Context_of_acquaintance   - None                     \n",
      "  8: Conflict                  - Synset('battle.n.01')    \n",
      "  9: non-combatant.n           - None                     \n",
      " 10: civilian.n                - Synset('civilian.n.01')  \n",
      " 11: civvie.n                  - None                     \n",
      "  0: Endeavor_failure          - None                     \n",
      "  1: Endeavor                  - Synset('attempt.n.01')   \n",
      "  2: Explanation               - Synset('explanation.n.01')\n",
      "  3: Time                      - Synset('time.v.02')      \n",
      "  4: Place                     - Synset('place.n.03')     \n",
      "  5: Circumstances             - Synset('circumstance.n.01')\n",
      "  6: Manner                    - Synset('manner.n.01')    \n",
      "  7: Containing_event          - None                     \n",
      "  8: Depictive                 - Synset('delineative.s.01')\n",
      "  9: Degree                    - Synset('degree.n.02')    \n",
      " 10: Means                     - Synset('think_of.v.04')  \n",
      " 11: fail.v                    - Synset('fail.v.01')      \n",
      " 12: flop.v                    - Synset('flop.v.01')      \n",
      " 13: collapse.v                - Synset('collapse.v.01')  \n",
      " 14: fold.v                    - Synset('fold.v.01')      \n",
      " 15: go under.v                - None                     \n",
      " 16: go bust.v                 - None                     \n",
      "  0: Inhibit_motion_scenario   - None                     \n",
      "  1: Agent                     - Synset('agent.n.01')     \n",
      "  2: Theme                     - Synset('subject.n.01')   \n",
      "  3: Holding_location          - None                     \n",
      "  4: Cause                     - Synset('cause.v.01')     \n",
      "  0: Scrutiny                  - Synset('examination.n.01')\n",
      "  1: Cognizer                  - None                     \n",
      "  2: Ground                    - Synset('footing.n.02')   \n",
      "  3: Phenomenon                - Synset('phenomenon.n.01')\n",
      "  4: Manner                    - Synset('manner.n.01')    \n",
      "  5: Means                     - Synset('means.n.01')     \n",
      "  6: Degree                    - Synset('degree.n.01')    \n",
      "  7: Direction                 - Synset('focus.n.01')     \n",
      "  8: Purpose                   - Synset('function.n.02')  \n",
      "  9: Medium                    - Synset('medium.n.07')    \n",
      " 10: Instrument                - Synset('instrument.n.03')\n",
      " 11: Time                      - Synset('time.n.02')      \n",
      " 12: analyse.v                 - Synset('analyze.v.01')   \n",
      " 13: analysis.n                - Synset('analysis.n.02')  \n",
      " 14: investigate.v             - Synset('investigate.v.01')\n",
      " 15: investigation.n           - Synset('investigation.n.02')\n",
      " 16: look.v                    - Synset('look.v.01')      \n",
      " 17: perusal.n                 - Synset('perusal.n.01')   \n",
      " 18: peruse.v                  - Synset('peruse.v.01')    \n",
      " 19: scan.v                    - Synset('scan.v.01')      \n",
      " 20: scrutinize.v              - Synset('size_up.v.01')   \n",
      " 21: scrutiny.n                - Synset('examination.n.01')\n",
      " 22: search.n                  - Synset('search.n.01')    \n",
      " 23: search.v                  - Synset('search.v.01')    \n",
      " 24: study.n                   - Synset('survey.n.01')    \n",
      " 25: study.v                   - Synset('analyze.v.01')   \n",
      " 26: survey.n                  - Synset('survey.n.01')    \n",
      " 27: survey.v                  - Synset('survey.v.01')    \n",
      " 28: analyst.n                 - Synset('analyst.n.01')   \n",
      " 29: probe.v                   - Synset('probe.v.01')     \n",
      " 30: reconnoitre.v             - Synset('scout.v.01')     \n",
      " 31: inspector.n               - Synset('inspector.n.01') \n",
      " 32: assay.v                   - Synset('assay.v.01')     \n",
      " 33: skim.v                    - Synset('plane.v.02')     \n",
      " 34: sift.v                    - Synset('sift.v.01')      \n",
      " 35: rummage.v                 - Synset('rummage.v.01')   \n",
      " 36: surveyor.n                - Synset('surveyor.n.01')  \n",
      " 37: scout.v                   - Synset('scout.v.01')     \n",
      " 38: eyeball.v                 - Synset('eye.v.01')       \n",
      " 39: check.v                   - Synset('see.v.10')       \n",
      " 40: sweep.v                   - Synset('brush.v.04')     \n",
      " 41: sweep.n                   - Synset('sweep.n.01')     \n",
      " 42: double-check.v            - Synset('double-check.v.01')\n",
      " 43: spy out the land.v        - None                     \n",
      " 44: once-over.n               - Synset('once-over.n.01') \n",
      " 45: comb.v                    - Synset('comb.v.01')      \n",
      " 46: frisk.v                   - Synset('frolic.v.01')    \n",
      " 47: ransack.v                 - Synset('plunder.v.03')   \n",
      " 48: scour.v                   - Synset('scour.v.01')     \n",
      " 49: monitor.v                 - Synset('monitor.v.01')   \n",
      " 50: analytic.a                - Synset('analytic.a.03')  \n",
      " 51: go [through].v            - None                     \n",
      " 52: monitoring.n              - Synset('monitoring.n.01')\n",
      " 53: unmonitored.a             - None                     \n",
      " 54: surveillance.n            - Synset('surveillance.n.01')\n",
      " 55: surveillance [entity].n   - None                     \n",
      " 56: explore.v                 - Synset('research.v.02')  \n",
      " 57: rifle.v                   - Synset('rifle.v.02')     \n",
      " 58: pry.v                     - Synset('pry.v.01')       \n",
      " 59: examination.n             - Synset('examination.n.01')\n",
      " 60: reconnaissance.n          - Synset('reconnaissance.n.01')\n"
     ]
    }
   ],
   "source": [
    "frame_list = []\n",
    "for idx in ids:\n",
    "    frame_list.append(MFrame(idx))\n",
    "for f in frame_list:\n",
    "    ctx = fn.frame(f.id)['definition'].replace('_', ' ')\n",
    "    for fe in f.fes:\n",
    "        ctx += f' {fe.replace(\"_\", \" \")}'\n",
    "    words = f.get_words()\n",
    "\n",
    "    for i, w in enumerate(words):\n",
    "        best_sense = lesk(w, ctx)\n",
    "        print(f'{i:3d}: {w:25s} - {str(best_sense):25s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I risultati ottenuti in output dall'algoritmo vanno quindi confrontati con le annotazioni svolte manualmente, di seguito sono riportati i sensi relativi ai termini dei primi due frame dell'esercitazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| id   | word             | sense                 | real annotation           |\n",
    "|------|------------------|-----------------------|---------------------------|\n",
    "| 12   | Feigning         | feign.v.01            |                           |\n",
    "| 12   | Agent            | agent.n.02            |                           |\n",
    "| 12   | Original         | original.n.02         |                           |\n",
    "| 12   | Copy             | copy.n.02             |                           |\n",
    "| 12   | Manner           | manner.n.01           |                           |\n",
    "| 12   | Means            | means.n.01            |                           |\n",
    "| 12   | Degree           | degree.n.01           |                           |\n",
    "| 12   | State of affairs | state_of_affairs.n.01 |                           |\n",
    "| 12   | Purpose          | purpose.n.03          |                           |\n",
    "| 12   | Explanation      | explanation.n.01      |                           |\n",
    "| 12   | Frequency        | frequency.n.03        |                           |\n",
    "| 12   | Time             | time.n.05             |                           |\n",
    "| 12   | iteration        | iteration.n.03        | Period_of_iterations      |\n",
    "| 12   | Duration         | duration.n.01         |                           |\n",
    "| 12   | Depictive        | deceptive.a.01        |                           |\n",
    "| 12   | Circumstances    | circumstance.n.02     |                           |\n",
    "| 12   | Place            | place.n.05            |                           |\n",
    "| 12   | counterfeit.v    | counterfeit.v.01      |                           |\n",
    "| 12   | fake.v           | fake.v.02             |                           |\n",
    "| 12   | feign.v          | feign.v.01            |                           |\n",
    "| 12   | stage.v          | stage.v.02            |                           |\n",
    "| 12   | affect.v         | affect.v.04           |                           |\n",
    "| 12   | pretend.v        | pretend.v.03          |                           |\n",
    "| 12   | simulate.v       | simulate.v.01         |                           |\n",
    "| 2615 | Noncombatant     | noncombatant.n.01     |                           |\n",
    "| 2615 | Origin           | origin.n.01           |                           |\n",
    "| 2615 | Person           | person.n.01           |                           |\n",
    "| 2615 | characteristic   | characteristic.n.01   | Persistent_characteristic |\n",
    "| 2615 | Descriptor       | descriptor.n.01       |                           |\n",
    "| 2615 | Age              | age.v.01              |                           |\n",
    "| 2615 | Ethnicity        | ethnicity.n.01        |                           |\n",
    "| 2615 | context          | context.n.02          | Context_of_acquaintance   |\n",
    "| 2615 | Conflict         | conflict.n.03         |                           |\n",
    "| 2615 | noncombatant.n   | noncombatant.n.01     | non-combatant.n           |\n",
    "| 2615 | civilian.n       | civilian.n.01         |                           |\n",
    "| 2615 | civilian         | civilian.n.01         | civvie.n                  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
