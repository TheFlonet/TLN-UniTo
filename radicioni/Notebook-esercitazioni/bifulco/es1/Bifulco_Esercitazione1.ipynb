{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual Similarity with WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:44:08.631839Z",
     "start_time": "2023-05-19T17:44:08.622372Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import semcor, stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from operator import itemgetter\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima operazione carichiamo in memoria il dataset fornito.\n",
    "\n",
    "Questo file csv contiene le coppie di termini e la similarità annotata (gold-standard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:41.885999Z",
     "start_time": "2023-05-19T17:38:41.662343Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./01-WordSim353.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante l'esercitazione verranno utilizzate tre differenti metriche per misurare la similarità tra sensi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wu & Palmer\n",
    "\n",
    "La misura di similarità di Wu & Palmer sfrutta la struttura ad albero di WordNet per calcolare la prossimità tra due sensi dati in input.\n",
    "\n",
    "$$sim_{wu-palmer}(s_1, s_2) = \\frac{2 \\cdot depth(LCS)}{depth(s_1) + depth(s_2)}$$\n",
    "\n",
    "Dove $LCS$ è il lowest common subsumer dei due sensi passati per argomento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def lcs(s1, s2):\n",
    "    lcs, h1, h2 = None, [s1], [s2]\n",
    "    for synset in h1:\n",
    "        s_hypernyms = synset.hypernyms()\n",
    "        if len(s_hypernyms) > 0:\n",
    "            h1.extend(s_hypernyms)\n",
    "    for synset in h2:\n",
    "        s_hypernyms = synset.hypernyms()\n",
    "        if len(s_hypernyms) > 0:\n",
    "            h2.extend(s_hypernyms)\n",
    "    if len(h1) > 0 and len(h2) > 0:\n",
    "        common = set(h1).intersection(set(h2))\n",
    "        if len(common) > 0:\n",
    "            common = [(s, s.max_depth() + 1) for s in common]\n",
    "            return sorted(common, key=itemgetter(1), reverse=True)[0][0]\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:41.892499Z",
     "start_time": "2023-05-19T17:38:41.678465Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Questa funzione lambda si occupa di ricavare la profondità di un senso passato in input."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "depth = lambda synset: max([len(path) for path in synset.hypernym_paths()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:41.892682Z",
     "start_time": "2023-05-19T17:38:41.683631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:41.892736Z",
     "start_time": "2023-05-19T17:38:41.690768Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_wu_palmer(s1, s2):\n",
    "    lcs_synset = lcs(s1, s2)\n",
    "    lcs_depth = lcs_synset.max_depth() + 1 if lcs_synset is not None else 0\n",
    "    d1 = depth(s1)\n",
    "    d2 = depth(s2)\n",
    "    if d1 > 0 or d2 > 0:\n",
    "        return (2 * lcs_depth) / (d1 + d2)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest Path\n",
    "\n",
    "La misura Shortest Path calcola la lunghezza del cammino tra i due nodi del grafo di WordNet corrispondenti ai *synset*.\n",
    "\n",
    "$$sim_{path}(s_1, s_2) = 2 \\cdot depthMax - len(s_1, s_2)$$\n",
    "\n",
    "Se la lunghezza del cammino è 0, ovvero i sensi sono sovrapposti, la similarità è massima. Quindi possiamo dire che è pari a 2*depthMax, ovvero due volte la massima profondità di WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per calcolare le due misure di similarità successive occorre la massima profondità dell'albero di WordNet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:43.546798Z",
     "start_time": "2023-05-19T17:38:41.704371Z"
    }
   },
   "outputs": [],
   "source": [
    "depth_max = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il metodo *min_len_path* calcola la distanza del percorso tra i due sensi. Tra i possibili cammini percorribili si sceglie quello passante per $LCS$, per cui forziamo il calcolo del percorso di lunghezza minima."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def min_len_path(s1, s2):\n",
    "    distance = 0\n",
    "    lcs_synset = lcs(s1, s2)\n",
    "    if lcs_synset is not None:\n",
    "        distance = (depth(s1) - depth(lcs_synset)) - (depth(s2) - depth(lcs_synset))\n",
    "    return distance\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:43.550928Z",
     "start_time": "2023-05-19T17:38:43.548106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:43.554773Z",
     "start_time": "2023-05-19T17:38:43.553170Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_shortest_path(s1, s2):\n",
    "    min_path = 0\n",
    "    len_path = min_len_path(s1, s2)\n",
    "    if len_path >= 0:\n",
    "        min_path = 2 * depth_max - len_path\n",
    "    return min_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lealcock & Chodorow\n",
    "\n",
    "Questa misura di similarità assume valori nell'intervallo (0, log(2*depthMax + 1)), l'aggiunta di 1 nell'argomento del logaritmo è per evitare lo zero.\n",
    "\n",
    "$$sim_{LC}(s_1, s_2) = - log \\frac{len(s_1, s_2)}{2 \\cdot depthMax}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:43.559624Z",
     "start_time": "2023-05-19T17:38:43.556380Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_leakcock_chodorow(s1, s2):\n",
    "    sim = 0\n",
    "    len_path = min_len_path(s1, s2)\n",
    "    if len_path > 0:\n",
    "        sim = -math.log(len_path / (2 * depth_max))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per praticità, nei test raccogliamo in una lista le coppie (funzione, nome) per le tre misure di similarità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:43.563260Z",
     "start_time": "2023-05-19T17:38:43.560522Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = [(sim_wu_palmer, 'Wu Palmer'),\n",
    " (sim_shortest_path, 'Shortest path'),\n",
    " (sim_leakcock_chodorow, 'Leakcock Chodorow')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutti i metodi sopra esposti hanno come argomento due sensi, tuttavia nel dataset preso in esame sono annotati dei termini.\n",
    "\n",
    "Per risolvere il problema, si considera un termine come il minimo contesto necessario e sufficiente per disambiguare l'altro membro della coppia.\n",
    "\n",
    "La similarità tra due termini, indipendentemente dal metodo utilizzato, sarà quindi il massimo tra ogni possibile coppia di sensi rappresentata dai due termini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:43.567808Z",
     "start_time": "2023-05-19T17:38:43.565349Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_similarity(t1, t2, sim_func):\n",
    "    synsets1 = wn.synsets(t1)\n",
    "    synsets2 = wn.synsets(t2)\n",
    "    max_sim = 0.0\n",
    "    best_pair = None\n",
    "    for s1 in synsets1:\n",
    "        for s2 in synsets2:\n",
    "            sim = sim_func(s1, s2)\n",
    "            if sim >= max_sim:\n",
    "                max_sim = sim\n",
    "                best_pair = (s1, s2)\n",
    "    return best_pair, max_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguiamo quindi le tre misure di similarità sull'intero dataset, calcolando la correlazione tra le similarità ottenute e quelle annotate tramite gli indici di Pearson e di Spearman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:44.630298Z",
     "start_time": "2023-05-19T17:38:43.591346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wu Palmer\n",
      "\tUnable to compute best senses pair between Maradona and football\n",
      "PearsonRResult(statistic=0.26572842333653923, pvalue=4.214296990970517e-07)\n",
      "SignificanceResult(statistic=0.324400489230381, pvalue=4.5457429629669424e-10)\n",
      "\n",
      "Shortest path\n",
      "\tUnable to compute best senses pair between Maradona and football\n",
      "PearsonRResult(statistic=-0.047634998203739294, pvalue=0.3729083492751214)\n",
      "SignificanceResult(statistic=-0.042286502469992174, pvalue=0.42900411307508346)\n",
      "\n",
      "Leakcock Chodorow\n",
      "\tUnable to compute best senses pair between Maradona and football\n",
      "PearsonRResult(statistic=-0.10971193205470338, pvalue=0.03966018541582094)\n",
      "SignificanceResult(statistic=-0.0992681329962518, pvalue=0.06282779628379778)\n"
     ]
    }
   ],
   "source": [
    "for sim_func, sim_name in similarities:\n",
    "    expected, obtained = [], []\n",
    "    print('\\n' + sim_name)\n",
    "    for idx, row in dataset.iterrows():\n",
    "        t1, t2 = row['Word 1'], row['Word 2']\n",
    "        expected_sim = row['Human (mean)']\n",
    "        sense_pair, similarity = compute_similarity(t1, t2, sim_func)\n",
    "        if sense_pair is None:\n",
    "            print(f'\\tUnable to compute best senses pair between {t1} and {t2}')\n",
    "        else:\n",
    "            expected.append(expected_sim)\n",
    "            obtained.append(similarity)\n",
    "    print(stats.pearsonr(expected, obtained))\n",
    "    print(stats.spearmanr(expected, obtained))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I dati presenti nel gold-standard non risultano altamente correlati con le similarità ricavate tramite le tre misure proposte. Questo fenomeno è spiegato dal fatto che gli approcci proposti non sono particolarmente raffinati. Inoltre, sfruttando in modo preponderante la struttura ad albero di WordNet, risentono dei problemi intrinseci della risorsa ovvero del fatto che i sensi non siano equamente densi su tutto il grafo.\n",
    "\n",
    "In tutte le misure testate, la coppia di termini (Maradona - football) non ha prodotto risultati. Questo è in linea con quanto atteso in quanto WordNet non indicizza persone fisiche tra i suoi sensi."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per questa parte dell'esercitazione si richiede di disambiguare i sensi partendo dai termini di un contesto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset utilizzato per questo problema è SemCor, scaricabile tramite la libreria nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:57:55.091219Z",
     "start_time": "2023-05-19T17:57:54.958163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting SemCor, this may take a while...\n"
     ]
    }
   ],
   "source": [
    "print('Getting SemCor, this may take a while...')\n",
    "semcor_corpus = semcor.sents()\n",
    "semcor_tags = semcor.tagged_sents(tag=\"sem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare di aggiungere rumore durante la computazione, è utile eliminare le stopwords dalle frasi analizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:44.765384Z",
     "start_time": "2023-05-19T17:38:44.764058Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(phrase):\n",
    "    phrase = phrase.split()\n",
    "    for p in string.punctuation:\n",
    "        phrase = {item.replace(p, '') for item in phrase}\n",
    "    phrase = {item.replace('\\'s', '') for item in phrase}\n",
    "    stop = stopwords.words('english')\n",
    "    return {t for t in phrase if t not in stop}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inoltre, per evitare estrazioni di contesti particolarmente difficili o particolarmente semplici verranno estratte frasi dal dataset in modo casuale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo *get_sentence_from_semcor* permette di estrarre la tripla (parola, frase/contesto, senso_target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:44.769592Z",
     "start_time": "2023-05-19T17:38:44.768552Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentence_from_semcor(sentence, tags):\n",
    "    for curr_word in range(len(tags)):\n",
    "        if isinstance(tags[curr_word], nltk.Tree) and \\\n",
    "                isinstance(tags[curr_word][0], str) and \\\n",
    "                isinstance(tags[curr_word].label(), nltk.corpus.reader.wordnet.Lemma):\n",
    "            word = tags[curr_word][0]\n",
    "            target = tags[curr_word].label().synset()\n",
    "            if target.pos() == 'n':\n",
    "                return word, sentence, target\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo *get_random_sentences* si occupa di estrarre 50 frasi del dataset. Le frasi estratte sono salvate in un insieme comune che non permette di estrarre la stessa frase una seconda volta.\n",
    "\n",
    "In questo modo si aumenta la varietà dei dati analizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:44.772831Z",
     "start_time": "2023-05-19T17:38:44.771711Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_idx = {-1}\n",
    "\n",
    "\n",
    "def get_random_sentences(corpus, tags):\n",
    "    max_n = len(corpus)\n",
    "    sentences = []\n",
    "    while len(sentences) < 50:\n",
    "        if len(selected_idx) == max_n:\n",
    "            raise Exception('Not enough data in remaining in the corpus')\n",
    "        idx = -1\n",
    "        while idx in selected_idx:\n",
    "            idx = random.randint(0, max_n - 1)\n",
    "        computed_tuple = get_sentence_from_semcor(corpus[idx], tags[idx])\n",
    "        selected_idx.add(idx)\n",
    "        if computed_tuple is not None:\n",
    "            sentences.append(computed_tuple)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per disambiguare i termini è stato utilizzato l'algoritmo Lesk con approccio bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:38:44.775928Z",
     "start_time": "2023-05-19T17:38:44.774703Z"
    }
   },
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "    synset = wn.synsets(word)\n",
    "    if synset is None or len(synset) == 0:\n",
    "        return None\n",
    "    guess = synset[0]\n",
    "    max_overlap = 0\n",
    "    for sense in synset:\n",
    "        signature = remove_stopwords(sense.definition())\n",
    "        for ex in sense.examples():\n",
    "            signature.union(remove_stopwords(ex))\n",
    "        overlap = len(signature.intersection(sentence))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            guess = sense\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, si esegue l'algoritmo e si calcola l'accuratezza media rispetto ai dati annotati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T17:39:07.515809Z",
     "start_time": "2023-05-19T17:38:44.778023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy: 50.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in tqdm(range(10)):\n",
    "    corpus_sentences = get_random_sentences(semcor_corpus, semcor_tags)\n",
    "    corpus_sentences = [(x[0], remove_stopwords(str(x[1])), x[2]) for x in corpus_sentences]\n",
    "    tp = 0\n",
    "    for s in corpus_sentences:\n",
    "        best_sense = lesk(s[0], s[1])\n",
    "        if best_sense is not None:\n",
    "            if best_sense == s[2]:\n",
    "                tp += 1\n",
    "    acc.append(float(tp*100)/float(len(corpus_sentences)))\n",
    "print(f'Avg accuracy: {sum(acc)/len(acc):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In media l'accuratezza ottenuta oscilla tra il 40% e il 50%. Per ottenere risultati migliori sarebbe necessario implementare la versione dell'algoritmo *corpus-Lesk*, in modo da riuscire a gestire sensi e non termini durante la computazione. Un ulteriore raffinamento potrebbe essere quello di espandere le frasi passate in input in modo da rendere più significativo l'overlap."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
