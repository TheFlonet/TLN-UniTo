{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Esercitazione 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tweet like (a) Trump"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:35.346977Z",
     "start_time": "2023-05-19T17:04:34.520725Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize, TreebankWordDetokenizer\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'esercitazione prevede di usare il dataset contenete circa 300 tweet, estratti dal profilo di Donald Trump, e generare un language model basato su n-grammi."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                 source                                               text  \\\n0    Twitter for iPhone                     LOSER! https://t.co/p5imhMJqS1   \n1    Twitter for iPhone  Most of the money raised by the RINO losers of...   \n2    Twitter for iPhone  ....because they don’t know how to win and the...   \n3    Twitter for iPhone  ....lost for Evan “McMuffin” McMullin (to me)....   \n4    Twitter for iPhone  ....get even for all of their many failures. Y...   \n..                  ...                                                ...   \n256  Twitter Web Client  .@Cher attacked @MittRomney. She is an average...   \n257  Twitter Web Client  Firing @lisalampanelli may have come as a surp...   \n258  Twitter Web Client  My @SquawkCNBC interview discussing why @MittR...   \n259           TweetDeck  I feel sorry for Rosie 's new partner in love ...   \n260           TweetDeck  The S&P are losers. They did this for personal...   \n\n              created_at  retweet_count  favorite_count is_retweet  \\\n0    05-18-2020 14:55:14          32295          135445      False   \n1    05-05-2020 18:18:26          19706           82425      False   \n2    05-05-2020 04:46:34          12665           56868      False   \n3    05-05-2020 04:46:34          13855           62268      False   \n4    05-05-2020 04:46:33           8122           33261      False   \n..                   ...            ...             ...        ...   \n256  05-10-2012 15:10:23            715             465      False   \n257  05-07-2012 02:58:18             45              19      False   \n258  03-06-2012 17:07:51             32               9      False   \n259  12-14-2011 16:45:55            667             463      False   \n260  08-09-2011 17:40:33            209              19      False   \n\n                  id_str  \n0    1262396333064892416  \n1    1257736426206031874  \n2    1257532112233803782  \n3    1257532114666508291  \n4    1257532110971318274  \n..                   ...  \n256   200603697435246592  \n257   199332301463748609  \n258   177078050750599168  \n259   146994336670822400  \n260   100984825103663104  \n\n[261 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>text</th>\n      <th>created_at</th>\n      <th>retweet_count</th>\n      <th>favorite_count</th>\n      <th>is_retweet</th>\n      <th>id_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Twitter for iPhone</td>\n      <td>LOSER! https://t.co/p5imhMJqS1</td>\n      <td>05-18-2020 14:55:14</td>\n      <td>32295</td>\n      <td>135445</td>\n      <td>False</td>\n      <td>1262396333064892416</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Twitter for iPhone</td>\n      <td>Most of the money raised by the RINO losers of...</td>\n      <td>05-05-2020 18:18:26</td>\n      <td>19706</td>\n      <td>82425</td>\n      <td>False</td>\n      <td>1257736426206031874</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Twitter for iPhone</td>\n      <td>....because they don’t know how to win and the...</td>\n      <td>05-05-2020 04:46:34</td>\n      <td>12665</td>\n      <td>56868</td>\n      <td>False</td>\n      <td>1257532112233803782</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Twitter for iPhone</td>\n      <td>....lost for Evan “McMuffin” McMullin (to me)....</td>\n      <td>05-05-2020 04:46:34</td>\n      <td>13855</td>\n      <td>62268</td>\n      <td>False</td>\n      <td>1257532114666508291</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Twitter for iPhone</td>\n      <td>....get even for all of their many failures. Y...</td>\n      <td>05-05-2020 04:46:33</td>\n      <td>8122</td>\n      <td>33261</td>\n      <td>False</td>\n      <td>1257532110971318274</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>Twitter Web Client</td>\n      <td>.@Cher attacked @MittRomney. She is an average...</td>\n      <td>05-10-2012 15:10:23</td>\n      <td>715</td>\n      <td>465</td>\n      <td>False</td>\n      <td>200603697435246592</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>Twitter Web Client</td>\n      <td>Firing @lisalampanelli may have come as a surp...</td>\n      <td>05-07-2012 02:58:18</td>\n      <td>45</td>\n      <td>19</td>\n      <td>False</td>\n      <td>199332301463748609</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>Twitter Web Client</td>\n      <td>My @SquawkCNBC interview discussing why @MittR...</td>\n      <td>03-06-2012 17:07:51</td>\n      <td>32</td>\n      <td>9</td>\n      <td>False</td>\n      <td>177078050750599168</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>TweetDeck</td>\n      <td>I feel sorry for Rosie 's new partner in love ...</td>\n      <td>12-14-2011 16:45:55</td>\n      <td>667</td>\n      <td>463</td>\n      <td>False</td>\n      <td>146994336670822400</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>TweetDeck</td>\n      <td>The S&amp;P are losers. They did this for personal...</td>\n      <td>08-09-2011 17:40:33</td>\n      <td>209</td>\n      <td>19</td>\n      <td>False</td>\n      <td>100984825103663104</td>\n    </tr>\n  </tbody>\n</table>\n<p>261 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('03-tweets.csv') # Caricamento del dataset\n",
    "display(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:35.358570Z",
     "start_time": "2023-05-19T17:04:35.347889Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per svolgere questo task siamo interessati solo alla colonna contenente i tweet. Di seguito si utilizzano le funzioni della libreria pandas per estrarre i dati rilevanti ed effettuare la tokenizzazione."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "trump_corpus = list(df['text'].apply(word_tokenize))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:35.418153Z",
     "start_time": "2023-05-19T17:04:35.359221Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per avere una rudimentale idea dei dati trattati, calcoliamo il numero medio di parole presenti in un tweet e di caratteri utilizzati."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(163, 26)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len, avg_word = sum([len(t) for t in df['text']]) // len(df), sum(len(t.split()) for t in df['text']) // len(df)\n",
    "avg_len, avg_word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:35.418416Z",
     "start_time": "2023-05-19T17:04:35.404180Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il parametro N indica la dimensione dell'n-gramma, in questo caso inizializzato a due.\n",
    "\n",
    "In questo modo verrà creata una tabella per stimare la probabilità di emissione di una parola data la precedente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "N = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:36.559044Z",
     "start_time": "2023-05-19T17:04:36.554190Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il metodo *padded_everygram_pipeline* permette di ottenere gli n-grammi per il modello e il vocabolario estratto dai dati, inoltre inserisce automaticamente i tag per effettuare il padding in modo da stimare correttamente anche come iniziare e concludere una frase."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "n_grams, vocabulary = padded_everygram_pipeline(N, trump_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:37.806340Z",
     "start_time": "2023-05-19T17:04:37.783818Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'addestramento di un language model basato su n-grammi si riduce al calcolo delle probabilità di emissione.\n",
    "\n",
    "Per calcolare tale matrice si usa il classico approccio dei modelli basati su n-grammi, al quale si applica la correzione di Laplace."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "trump_model = Laplace(N)\n",
    "trump_model.fit(n_grams, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:39.330446Z",
     "start_time": "2023-05-19T17:04:39.255815Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il metodo *generate_sent* permette di generare una frase specificandone la lunghezza, rimuovendo i tag per il padding in modo da rendere verosimile l'output."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_sent(model, random_seed, num_words):\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return TreebankWordDetokenizer().detokenize(content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:04:48.457520Z",
     "start_time": "2023-05-19T17:04:48.442841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in race that you in the American dream!\n"
     ]
    }
   ],
   "source": [
    "print(generate_sent(trump_model, 5, num_words=avg_word))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:05:50.556830Z",
     "start_time": "2023-05-19T17:05:50.552820Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In modo analogo, il modello può essere addestrato con valori di N variabili, a seguire un esempio con N = 3."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest -and you all know it!\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "n_grams, vocabulary = padded_everygram_pipeline(N, trump_corpus)\n",
    "trump_model = Laplace(N)\n",
    "trump_model.fit(n_grams, vocabulary)\n",
    "\n",
    "print(generate_sent(trump_model, 5, num_words=avg_word))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T17:05:57.011259Z",
     "start_time": "2023-05-19T17:05:56.971077Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In sintesi, i modelli linguistici basati su n-grammi sono estremamente veloci e semplici da addestrare. Tuttavia, rispetto a modelli più sofisticati, presentano evidenti limiti nella generazione di testi.\n",
    "\n",
    "Tali limiti sono dovuti all'approccio puramente statistico, che si limita a produrre la n-esima parola data una \"storia\" di n-1 termini."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
